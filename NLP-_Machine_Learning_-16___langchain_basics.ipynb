{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa2f8212",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-08T08:19:49.294037Z",
     "start_time": "2023-04-08T08:19:47.533476Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<!-- Many of the styles here are inspired by: \n",
       "    https://towardsdatascience.com/10-practical-tips-you-need-to-know-to-personalize-jupyter-notebook-fbd202777e20 \n",
       "       \n",
       "    \n",
       "    On the author's local machine, these exist in the custom.css file. However, in order to keep uniform look and feel, \n",
       "    and at the request of participants, I have added it to this common import-file here.\n",
       "\n",
       "    -->\n",
       "\n",
       "<link href=\"https://fonts.googleapis.com/css?family=Lora:400,700|Montserrat:300\" rel=\"stylesheet\">\n",
       "\n",
       "<link href=\"https://fonts.googleapis.com/css2?family=Crimson+Pro&family=Literata&display=swap\" rel=\"stylesheet\">\n",
       "<style>\n",
       "\n",
       "\n",
       "#ipython_notebook::before{\n",
       " content:\"NLP with Transformers\";\n",
       "        color: white;\n",
       "        font-weight: bold;\n",
       "        text-transform: uppercase;\n",
       "        font-family: 'Lora',serif;\n",
       "        font-size:16pt;\n",
       "        margin-bottom:15px;\n",
       "        margin-top:15px;\n",
       "           \n",
       "}\n",
       "body > #header {\n",
       "    #background: #D15555;\n",
       "    background: linear-gradient(to bottom, indianred 0%, #fff 100%);\n",
       "    opacity: 0.8;\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       ".navbar-default .navbar-nav > li > a, #kernel_indicator {\n",
       "    color: white;\n",
       "    transition: all 0.25s;\n",
       "    font-size:10pt;\n",
       "    font-family: sans-serif;\n",
       "    font-weight:normal;\n",
       "}\n",
       ".navbar-default {\n",
       "    padding-left:100px;\n",
       "    background: none;\n",
       "    border: none;\n",
       "}\n",
       "\n",
       "\n",
       "body > menubar-container {\n",
       "    background-color: wheat;\n",
       "}\n",
       "#ipython_notebook img{                                                                                        \n",
       "    display:block; \n",
       "    \n",
       "    background: url(\"https://www.supportvectors.com/wp-content/uploads/2016/03/logo-poster-smaller.png\") no-repeat;\n",
       "    background-size: contain;\n",
       "   \n",
       "    padding-left: 600px;\n",
       "    padding-right: 100px;\n",
       "    \n",
       "    -moz-box-sizing: border-box;\n",
       "    box-sizing: border-box;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "body {\n",
       " #font-family:  'Literata', serif;\n",
       "    font-family:'Lora', san-serif;\n",
       "    text-align: justify;\n",
       "    font-weight: 400;\n",
       "    font-size: 12pt;\n",
       "}\n",
       "\n",
       "iframe{\n",
       "    width:100%;\n",
       "    min-height:600px;\n",
       "}\n",
       "\n",
       "h1, h2, h3, h4, h5, h6 {\n",
       "# font-family: 'Montserrat', sans-serif;\n",
       " font-family:'Lora', serif;\n",
       " font-weight: 200;\n",
       " text-transform: uppercase;\n",
       " color: #EC7063 ;\n",
       "}\n",
       "\n",
       "h2 {\n",
       "    color: #000080;\n",
       "}\n",
       "\n",
       ".checkpoint_status, .autosave_status {\n",
       "    color:wheat;\n",
       "}\n",
       "\n",
       "#notebook_name {\n",
       "    font-weight: 600;\n",
       "    font-size:20pt;\n",
       "    text-variant:uppercase;\n",
       "    color: wheat; \n",
       "    margin-right:20px;\n",
       "    margin-left:-500px;\n",
       "}\n",
       "#notebook_name:hover {\n",
       "background-color: salmon;\n",
       "}\n",
       "\n",
       "\n",
       ".dataframe { /* dataframe atau table */\n",
       "    background: white;\n",
       "    box-shadow: 0px 1px 2px #bbb;\n",
       "}\n",
       ".dataframe thead th, .dataframe tbody td {\n",
       "    text-align: center;\n",
       "    padding: 1em;\n",
       "}\n",
       "\n",
       ".checkpoint_status, .autosave_status {\n",
       "    color:wheat;\n",
       "}\n",
       "\n",
       ".output {\n",
       "    align-items: center;\n",
       "}\n",
       "\n",
       "div.cell {\n",
       "    transition: all 0.25s;\n",
       "    border: none;\n",
       "    position: relative;\n",
       "    top: 0;\n",
       "}\n",
       "div.cell.selected, div.cell.selected.jupyter-soft-selected {\n",
       "    border: none;\n",
       "    background: transparent;\n",
       "    box-shadow: 0 6px 18px #aaa;\n",
       "    z-index: 10;\n",
       "    top: -10px;\n",
       "}\n",
       ".CodeMirror pre, .CodeMirror-dialog, .CodeMirror-dialog .CodeMirror-search-field, .terminal-app .terminal {\n",
       "    font-family: 'Hack' , serif; \n",
       "    font-weight: 500;\n",
       "    font-size: 14pt;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "</style>    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "<center><img src=\"https://d4x5p7s4.rocketcdn.me/wp-content/uploads/2016/03/logo-poster-smaller.png\"/> </center>\n",
       "<div style=\"color:#aaa;font-size:8pt\">\n",
       "<hr/>\n",
       "&copy; SupportVectors. All rights reserved. <blockquote>This notebook is the intellectual property of SupportVectors, and part of its training material. \n",
       "Only the participants in SupportVectors workshops are allowed to study the notebooks for educational purposes currently, but is prohibited from copying or using it for any other purposes without written permission.\n",
       "\n",
       "<b> These notebooks are chapters and sections from Asif Qamar's textbook that he is writing on Data Science. So we request you to not circulate the material to others.</b>\n",
       " </blockquote>\n",
       " <hr/>\n",
       "</div>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run supportvectors-common.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71c6b6a",
   "metadata": {},
   "source": [
    "# Getting started with `LangChain`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ce7871",
   "metadata": {},
   "source": [
    "### Learning goals\n",
    "\n",
    "We will learn the basics of:\n",
    "    \n",
    "* what is a `langchain`, and what purpose it serves\n",
    "* a simple prompt template\n",
    "* a simple agent that does something useful\n",
    "\n",
    "## Environment setup\n",
    "\n",
    "There are two steps needed to get started:\n",
    "\n",
    "* install the necessary libraries\n",
    "* get the necessary api keys, and set them as environment variables on our workstation.\n",
    "\n",
    "#### Library installation\n",
    "\n",
    "Run the following cell only once, to install the libraries. After that, comment it out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aa9ef09",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /home/jai/anaconda3/lib/python3.10/site-packages (0.0.285)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/jai/anaconda3/lib/python3.10/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/jai/anaconda3/lib/python3.10/site-packages (from langchain) (2.3.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/jai/.local/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /home/jai/anaconda3/lib/python3.10/site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/jai/anaconda3/lib/python3.10/site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/jai/anaconda3/lib/python3.10/site-packages (from langchain) (2.28.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/jai/anaconda3/lib/python3.10/site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /home/jai/anaconda3/lib/python3.10/site-packages (from langchain) (0.5.14)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/jai/anaconda3/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/jai/anaconda3/lib/python3.10/site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.21 in /home/jai/anaconda3/lib/python3.10/site-packages (from langchain) (0.0.35)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jai/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/jai/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/jai/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/jai/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/jai/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jai/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/jai/anaconda3/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/jai/anaconda3/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: pydantic-core==2.6.3 in /home/jai/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.6.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/jai/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/jai/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jai/anaconda3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jai/anaconda3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jai/anaconda3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/jai/anaconda3/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/jai/anaconda3/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (22.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/jai/anaconda3/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (0.4.3)\n",
      "Requirement already satisfied: google-search-results in /home/jai/anaconda3/lib/python3.10/site-packages (2.4.2)\n",
      "Requirement already satisfied: requests in /home/jai/anaconda3/lib/python3.10/site-packages (from google-search-results) (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jai/anaconda3/lib/python3.10/site-packages (from requests->google-search-results) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/jai/anaconda3/lib/python3.10/site-packages (from requests->google-search-results) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jai/anaconda3/lib/python3.10/site-packages (from requests->google-search-results) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jai/anaconda3/lib/python3.10/site-packages (from requests->google-search-results) (3.4)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Uncomment this only if needed.\n",
    "#\n",
    "!pip install langchain --upgrade\n",
    "!pip install google-search-results --upgrade\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90e0243",
   "metadata": {},
   "source": [
    "#### Needed Imports\n",
    "Let us now import the necessary components for this lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3785d1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b> Libraries installed, and components imported </b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate, FewShotPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.agents import load_tools, initialize_agent, AgentType\n",
    "from IPython.display import Markdown, HTML\n",
    "\n",
    "display(HTML('<b> Libraries installed, and components imported </b>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44dbef2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## OpenAI and SERP API keys\n",
    "\n",
    "In order to be able to use some of the large language models, let us register with the `openai` website and get an api key. Likewise, let's do the same for `serpapi`. The respective website are:\n",
    "\n",
    "* **SerpApi**: https://serpapi.com/ Register at this site, and then login. The look for your developer api key, and copy it.\n",
    "\n",
    "* **OpenAI**: https://platform.openai.com/account/api-keys Create a key, and be careful that you digitally note it down immediately -- you won't be able to see it later.\n",
    "\n",
    "<div class=\"alert-box alert-warning\" style=\"padding-top:30px\">\n",
    "   \n",
    "<b >Caveat Emptor</b>\n",
    "\n",
    ">Be careful not to share these keys publicly! They are associated with your account -- and after you have exhausted your free tokens, the respective api providers meter your usage, and charge you accordingly.\n",
    ">\n",
    ">For this reason, it is a particularly bad idea to hard-wire it in your jupyter notebooks: sooner or later, you will end up sharing your notebook more widely than you intended. In that eventuality, you incur the risk of raking of large bills from the api providers for use by unauthorized people on your behalf.\n",
    "</div>\n",
    "\n",
    "\n",
    "Then, we need to add two environment variables `OPENAI_API_KEY` on our workstation:\n",
    "\n",
    "* `OPENAI_API_KEY` for the OpenAI api key\n",
    "* `SERPAPI_API_KEY` for the SerpApi key\n",
    "\n",
    "\n",
    "For Linux distributions and Mac, one way to accomplish this is to add the following line to one of the `~/.bashrc`,  `~/.bash_profile`, `~/.profile`, or `~/.zshrc` files, based on the shell and distribution you are using.\n",
    "\n",
    "```\n",
    "export OPENAI_API_KEY=\"<<your openai-api-key>>\"\n",
    "export SERPAPI_API_KEY=\"<<your serpapi key>>\"\n",
    "```\n",
    "\n",
    "For MS-Windows, try setting these environment variables with the following steps:\n",
    "\n",
    "* launch the control panel\n",
    "* go to `System -> Advanced settings -> Environment variables`\n",
    "* Add the new environment variables\n",
    "* Quite likely, on windows, you will need to restart the jupyter kernel for the notebook to pick up the envronment variables.\n",
    "\n",
    "\n",
    "#### Instantiate a large language model\n",
    "\n",
    "Now, let us instantiate an `OpenAI` object that will use the large language model that the OpenAI provides as a remote api service. To help it produce rather varied results, we have set the `temperature` high. More about the meaning of temperature in the next lab -- for now, it suffices us to take it for granted that this value will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3d0a176-31b1-43fa-9f25-fea866297b95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20eb26cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927b98d3",
   "metadata": {},
   "source": [
    "#### Invoke the LLM to generate text\n",
    "\n",
    "The `OpenAI` large language model is generative: so it responds with a textual output to input prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f868201d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Twisted Tail\n"
     ]
    }
   ],
   "source": [
    "text = \"What is a good name for a cute mobius strip?\"\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08d09f8",
   "metadata": {},
   "source": [
    "Next time we make the same invocation, we should expect a different result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4016743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Twisty Turnaround\n"
     ]
    }
   ],
   "source": [
    "text = \"What is a good name for a cute mobius strip?\"\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47f16f4",
   "metadata": {},
   "source": [
    "## Prompt\n",
    "\n",
    "A prompt is a template, with placeholders for user inputs. In the following, let us get a brief preview of how it works. We will start by creating a prompt, that expects a user-input called `book`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55abacdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"book\"],\n",
    "    template=\"Who is the author of the book {book}?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884b8734",
   "metadata": {},
   "source": [
    "Now, we can have it produce text to go into the large language model by supplying a value for the input variable `book`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc415e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is the author of the book A snail of two cities?\n"
     ]
    }
   ],
   "source": [
    "text = prompt.format(book = 'A snail of two cities')\n",
    "print (text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde6d0f7",
   "metadata": {},
   "source": [
    "and finally, pass the output of the prompt to the large language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5944cc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The book A Snail of Two Cities was written by Lola M. Schaefer.\n"
     ]
    }
   ],
   "source": [
    "author = llm(text)\n",
    "print (author)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9312d0a",
   "metadata": {},
   "source": [
    "## LLM Chain\n",
    "\n",
    "Now, we could create a useful chain by concatenating the two components, prompt and the large language model. When we do so, it become a reusable component, and we do not have to ferry the output of one component (the prompt here) to be the input to the second component (the large language model).\n",
    "\n",
    "Let us see now we can create this very simple chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d278a2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The author of the book A Snail of Two Cities is Kenneth Baker.\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "author = chain.run('A snail of two cities')\n",
    "print(author)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133b0181",
   "metadata": {},
   "source": [
    "## Agents\n",
    "\n",
    "Agents in `langchain` provide an ability to call chains conditional on the user inputs. In other words, based on the context, the agent determines which tools and LLMs they need to use. This creates flexible and dynamic chains, thus providing us considerably powerful ways to engage with these models.\n",
    "\n",
    "In other words, `langchain` derives its power from the interplay of three entities:\n",
    "\n",
    "* **Large Language Models**: the large language models powering the agent\n",
    "* **Tools**: a tool is simply a function that does something useful -- such as perform a google search, retrieve something from a database, run a `REPL`, or fire other chains. The basic signature of the function comprises a string as input, and a string as output. This leaves considerable latitude in implementing tools.\n",
    "* **Agents**: agents handle the overall orchestration or flow control, based on context and user input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad746e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_names = ['serpapi',   # for google search\n",
    "              'llm-math'  # this particular tool needs an llm too, so need to pass that\n",
    "             ]\n",
    "\n",
    "tools = load_tools (tool_names = tool_names, \n",
    "                    llm        = llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860d5665",
   "metadata": {},
   "source": [
    "Now that we have the tools, and a large language model available, let us orchestrate them with an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "255017bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent (tools   = tools, \n",
    "                          llm     = llm,\n",
    "                          agent   = AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "                          verbose = True\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80c45de",
   "metadata": {},
   "source": [
    "Let us start with the following prompt text:\n",
    "\n",
    "> What is the height of mount everest in meters? If an aeroplane has to travel 1 km higher than that number, how high should it be?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39afe361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should look up the current height of Mount Everest first\n",
      "Action: Search\n",
      "Action Input: \"Height of Mount Everest\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m29,032′\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to convert this to meters\n",
      "Action: Calculator\n",
      "Action Input: 29,032' in meters\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 8848.9536\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now need to add 1 km\n",
      "Action: Calculator\n",
      "Action Input: 8848.9536 + 1000\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 9848.9536\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The aeroplane should be 9,848.9536 meters high to be 1 km higher than Mount Everest.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The aeroplane should be 9,848.9536 meters high to be 1 km higher than Mount Everest.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"\"\"\n",
    "What is the height of mount everest in meters today? \n",
    "If an aeroplane has to travel 1 km higher than\n",
    "that number, how high should it be?\n",
    "\"\"\"\n",
    "\n",
    "agent.run(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88723b5",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "* note that we forced the agent to use the search tool, since we implied that the height of the Everest keeps changing, and we need to know the height today\n",
    "* the search tool returned the height in imperial units (feet)\n",
    "* so there was a need to first convert it to SI units (meter)\n",
    "* finally, the math tool had to add a 1000 meters to the value to figure out the answer.\n",
    "\n",
    "#### Homework\n",
    "\n",
    "What would have happened if we did not specify `today` in the question? Try it out. Explain why it is that way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "728bf532-611b-4897-ad79-097169b9ba52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should find out the height of mount everest first\n",
      "Action: Search\n",
      "Action Input: \"height of mount everest\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m29,032′\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I can now use a calculator to figure out the height in meters\n",
      "Action: Calculator\n",
      "Action Input: 29,032 ft\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 95249.34688\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to add 1 km to that\n",
      "Action: Calculator\n",
      "Action Input: 95249.34688 + 1000\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 96249.34688\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The aeroplane should fly at a height of 96249.34688 meters.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The aeroplane should fly at a height of 96249.34688 meters.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"\"\"\n",
    "What is the height of mount everest in meters? \n",
    "If an aeroplane has to travel 1 km higher than\n",
    "that number, how high should it be?\n",
    "\"\"\"\n",
    "\n",
    "agent.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7536fb18-0fc8-40d0-bf43-3db89e60f54a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
