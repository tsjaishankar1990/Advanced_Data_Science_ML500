{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa2f8212",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-08T08:19:49.294037Z",
     "start_time": "2023-04-08T08:19:47.533476Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<!-- Many of the styles here are inspired by: \n",
       "    https://towardsdatascience.com/10-practical-tips-you-need-to-know-to-personalize-jupyter-notebook-fbd202777e20 \n",
       "       \n",
       "    \n",
       "    On the author's local machine, these exist in the custom.css file. However, in order to keep uniform look and feel, \n",
       "    and at the request of participants, I have added it to this common import-file here.\n",
       "\n",
       "    -->\n",
       "\n",
       "<link href=\"https://fonts.googleapis.com/css?family=Lora:400,700|Montserrat:300\" rel=\"stylesheet\">\n",
       "\n",
       "<link href=\"https://fonts.googleapis.com/css2?family=Crimson+Pro&family=Literata&display=swap\" rel=\"stylesheet\">\n",
       "<style>\n",
       "\n",
       "\n",
       "#ipython_notebook::before{\n",
       " content:\"NLP with Transformers\";\n",
       "        color: white;\n",
       "        font-weight: bold;\n",
       "        text-transform: uppercase;\n",
       "        font-family: 'Lora',serif;\n",
       "        font-size:16pt;\n",
       "        margin-bottom:15px;\n",
       "        margin-top:15px;\n",
       "           \n",
       "}\n",
       "body > #header {\n",
       "    #background: #D15555;\n",
       "    background: linear-gradient(to bottom, indianred 0%, #fff 100%);\n",
       "    opacity: 0.8;\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       ".navbar-default .navbar-nav > li > a, #kernel_indicator {\n",
       "    color: white;\n",
       "    transition: all 0.25s;\n",
       "    font-size:10pt;\n",
       "    font-family: sans-serif;\n",
       "    font-weight:normal;\n",
       "}\n",
       ".navbar-default {\n",
       "    padding-left:100px;\n",
       "    background: none;\n",
       "    border: none;\n",
       "}\n",
       "\n",
       "\n",
       "body > menubar-container {\n",
       "    background-color: wheat;\n",
       "}\n",
       "#ipython_notebook img{                                                                                        \n",
       "    display:block; \n",
       "    \n",
       "    background: url(\"https://www.supportvectors.com/wp-content/uploads/2016/03/logo-poster-smaller.png\") no-repeat;\n",
       "    background-size: contain;\n",
       "   \n",
       "    padding-left: 600px;\n",
       "    padding-right: 100px;\n",
       "    \n",
       "    -moz-box-sizing: border-box;\n",
       "    box-sizing: border-box;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "body {\n",
       " #font-family:  'Literata', serif;\n",
       "    font-family:'Lora', san-serif;\n",
       "    text-align: justify;\n",
       "    font-weight: 400;\n",
       "    font-size: 12pt;\n",
       "}\n",
       "\n",
       "iframe{\n",
       "    width:100%;\n",
       "    min-height:600px;\n",
       "}\n",
       "\n",
       "h1, h2, h3, h4, h5, h6 {\n",
       "# font-family: 'Montserrat', sans-serif;\n",
       " font-family:'Lora', serif;\n",
       " font-weight: 200;\n",
       " text-transform: uppercase;\n",
       " color: #EC7063 ;\n",
       "}\n",
       "\n",
       "h2 {\n",
       "    color: #000080;\n",
       "}\n",
       "\n",
       ".checkpoint_status, .autosave_status {\n",
       "    color:wheat;\n",
       "}\n",
       "\n",
       "#notebook_name {\n",
       "    font-weight: 600;\n",
       "    font-size:20pt;\n",
       "    text-variant:uppercase;\n",
       "    color: wheat; \n",
       "    margin-right:20px;\n",
       "    margin-left:-500px;\n",
       "}\n",
       "#notebook_name:hover {\n",
       "background-color: salmon;\n",
       "}\n",
       "\n",
       "\n",
       ".dataframe { /* dataframe atau table */\n",
       "    background: white;\n",
       "    box-shadow: 0px 1px 2px #bbb;\n",
       "}\n",
       ".dataframe thead th, .dataframe tbody td {\n",
       "    text-align: center;\n",
       "    padding: 1em;\n",
       "}\n",
       "\n",
       ".checkpoint_status, .autosave_status {\n",
       "    color:wheat;\n",
       "}\n",
       "\n",
       ".output {\n",
       "    align-items: center;\n",
       "}\n",
       "\n",
       "div.cell {\n",
       "    transition: all 0.25s;\n",
       "    border: none;\n",
       "    position: relative;\n",
       "    top: 0;\n",
       "}\n",
       "div.cell.selected, div.cell.selected.jupyter-soft-selected {\n",
       "    border: none;\n",
       "    background: transparent;\n",
       "    box-shadow: 0 6px 18px #aaa;\n",
       "    z-index: 10;\n",
       "    top: -10px;\n",
       "}\n",
       ".CodeMirror pre, .CodeMirror-dialog, .CodeMirror-dialog .CodeMirror-search-field, .terminal-app .terminal {\n",
       "    font-family: 'Hack' , serif; \n",
       "    font-weight: 500;\n",
       "    font-size: 14pt;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "</style>    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "<center><img src=\"https://d4x5p7s4.rocketcdn.me/wp-content/uploads/2016/03/logo-poster-smaller.png\"/> </center>\n",
       "<div style=\"color:#aaa;font-size:8pt\">\n",
       "<hr/>\n",
       "&copy; SupportVectors. All rights reserved. <blockquote>This notebook is the intellectual property of SupportVectors, and part of its training material. \n",
       "Only the participants in SupportVectors workshops are allowed to study the notebooks for educational purposes currently, but is prohibited from copying or using it for any other purposes without written permission.\n",
       "\n",
       "<b> These notebooks are chapters and sections from Asif Qamar's textbook that he is writing on Data Science. So we request you to not circulate the material to others.</b>\n",
       " </blockquote>\n",
       " <hr/>\n",
       "</div>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run supportvectors-common.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85541636",
   "metadata": {},
   "source": [
    "## <img src=\"https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.png\" width=\"60px\">  Fine tuning the Transformers\n",
    "\n",
    "Sometimes, a pretrained model may not exactly fit our task, and so the inference performance will leave scope for improvement. At such a time, if additional task-specific training data is available, we can fine tune the models. This is the second part of the transfer learning journey: take a pretrained model, and fine tune it by further training it on a task-specific dataset for a few epochs.\n",
    "\n",
    "It is worth noting that, for pre-training the models, the process is oftentimes self-supervised. In other words, labeled data is not necessary. For example, we can pre-train the masked language models simply by taking a vast corpus of documents, decompose them into sentences. Each sentence then becomes the datum for pre-training as an `<input, label>` pair, simply by randomly masking a few words, and treating the masked words as labels.\n",
    "\n",
    "Therefore, pre-training is done with:\n",
    "\n",
    "* vast quantities of data, and consequently large number of training steps over the mini-batches\n",
    "* using unlabeled data most of the time (i.e., as self-supervised learning), by cleverly extracting `<input, label>` pairs as training data instances from the data\n",
    "\n",
    "On the other hand, the fine-tuning of the models involves:\n",
    "\n",
    "* availability of labeled data for the specific task\n",
    "* the dataset sizes are **generally not needed to be big -- indeed, small datasets mostly suffice.**\n",
    "* running a much shorter training cycle, with a few epochs over the task-specific data\n",
    "* **far less hardware resource**\n",
    "* because of the above, two far less model (fine-tuning) training time\n",
    "* and causes a **far smaller carbon footprint or environmental impact**!\n",
    "\n",
    "\n",
    "Therefore, wherever feasible, we should resort to transfer learning, and therefore, fine-tuning of the pretrained models as our preferred approach.\n",
    "\n",
    "The `Huggingface` core libraries makes it rather easily to fine-tune the pretrained models. For this, we will use the following libraries:\n",
    "\n",
    "* `datasets` the library that makes it easy to load and use a vast number of publicly available datasets, many of which belong to well-known benchmarks. For example, in this lab we will use the `mrpc` dataset from the `GLUE` benchmark for nlp tasks.\n",
    "\n",
    "* `transformers` the main library of models and tokenizers, etc.\n",
    "\n",
    "* `evaluate` an excellent library to evaluate the inference performance of the trained models, and to compare performances across models.\n",
    "\n",
    "#### Installation\n",
    "\n",
    "Quite likey, by now you have installed each of the below library on your workstation. Otherwise, uncomment the below cell and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aa9ef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Uncomment this only if needed.\n",
    "#\n",
    "#!pip install datasets transformers evaluate --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1389b0",
   "metadata": {},
   "source": [
    "### Load the `mrpc` dataset\n",
    "This dataset contains sentence-pairs; the label specifies whether the second sentence is the paraphrase of the first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9570317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f553de1f",
   "metadata": {},
   "source": [
    "Let us explore it a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dc311ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576dc37b",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "The `raw_datasets` comprises of three datasets (`train`, `validation`, `test`), stored in a dictionary `DatasetDict` object. This is rather convenient, since it has already been split into the train-validate-test subsets.\n",
    "\n",
    "We also note that there only `3668 + 408 + 1725 = 5801` instances of data. This is a considerably smaller dataset, and only `3668` for fine-tuning a pre-trained model.\n",
    "\n",
    "Also note that the input $\\mathbf{X}$ is derived from a pair of sentences `<sentence1, sentence2>`. The ouput is, of-course, marked as the `label`.\n",
    "\n",
    "\n",
    "### Load pretrained models\n",
    "\n",
    "Let us now load the pretrained tokenizer and transformer models. This is nearly identical to what we did in the previous labs.\n",
    "\n",
    "There is however a subtlety when using the tokenizer. So far, we have been passing only one sentence to the tokenizer. But here we have pairs of sentences in this dataset. Fortunately, the tokenizers for `BERT` do accept pairs of sentences.\n",
    "\n",
    "Recall that in the original exploration of the `BERT` research paper, we saw how the model was pre-trained using inputs as  sentence pairs.\n",
    "\n",
    "#### Data Collator\n",
    "\n",
    "Observe a new animal we introduced to our zoo here, the `DataCollatorWithPadding`.\n",
    "\n",
    "Data collators are responsible for forming (mini-) batches of the datasets. They preserve the form of the original data, but may perform some post-processing as needed.\n",
    "\n",
    "For example, in our task, the sentences may be of variable length. So the `DataCollatorWithPadding` will pad each of the tokenized sequences in a mini-batch so that its length is that of the large sequence present in that mini-batch.\n",
    "\n",
    "<img src=\"images/data-prep-for-fine-tuning.jpeg\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eccbf8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12661fa868f64f2299ed9f4208797163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d0b86e",
   "metadata": {},
   "source": [
    "#### Load the pretrained model checkpoint\n",
    "\n",
    "Next we load a pre-trained model checkpoint, that is specific to the sequence classification task.\n",
    "\n",
    "> The classification task here: inferring whether the `sentence2` is a **paraphrasing** of the `sentence1` for a given input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be9ce58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88b4d39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1377' max='1377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1377/1377 16:17, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.528700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.329300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1377, training_loss=0.369309646285091, metrics={'train_runtime': 978.0259, 'train_samples_per_second': 11.251, 'train_steps_per_second': 1.408, 'total_flos': 405258858573360.0, 'train_loss': 0.369309646285091, 'epoch': 3.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\"test-trainer\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809f7f3b",
   "metadata": {},
   "source": [
    "### `Evaluate` library to compute model metrics\n",
    "\n",
    "The `evaluate` library proves very helpful here in computing the model performance metrics. Now, each dataset has its relevant metric for the task the model is trained for. In this case, it is `accuracy` and `F1` score. We can instantiate a `metric` object from a dataset, in much the same way that we used the `datasets.load()` to load the data.\n",
    "\n",
    "The `compute()` method takes as arguments what you would expect: the predictions and the ground-truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c11e2a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337adf6d",
   "metadata": {},
   "source": [
    "### The `Trainer` \n",
    "\n",
    "The trainer finally takes all the parts one would expect:\n",
    "\n",
    "* some specific training arguments, such as the name of the training run, an evaluation-strategy, etc.\n",
    "* `model` -- the model to train or fine tune\n",
    "* the training and validation datasets\n",
    "* the tokenizer\n",
    "* the relevant data collator\n",
    "* the function to compute the metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9119b0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\"test-trainer\", evaluation_strategy=\"epoch\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3af099",
   "metadata": {},
   "source": [
    "### Fine-tune the model\n",
    "\n",
    "In order to fine-tune the pre-trained model, let the `trainer` now fire off the training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e67613c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'evaluate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mevaluate\u001b[39;00m\n\u001b[1;32m      2\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'evaluate'"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
