{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa2f8212",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-08T08:19:49.294037Z",
     "start_time": "2023-04-08T08:19:47.533476Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<!-- Many of the styles here are inspired by: \n",
       "    https://towardsdatascience.com/10-practical-tips-you-need-to-know-to-personalize-jupyter-notebook-fbd202777e20 \n",
       "       \n",
       "    \n",
       "    On the author's local machine, these exist in the custom.css file. However, in order to keep uniform look and feel, \n",
       "    and at the request of participants, I have added it to this common import-file here.\n",
       "\n",
       "    -->\n",
       "\n",
       "<link href=\"https://fonts.googleapis.com/css?family=Lora:400,700|Montserrat:300\" rel=\"stylesheet\">\n",
       "\n",
       "<link href=\"https://fonts.googleapis.com/css2?family=Crimson+Pro&family=Literata&display=swap\" rel=\"stylesheet\">\n",
       "<style>\n",
       "\n",
       "\n",
       "#ipython_notebook::before{\n",
       " content:\"NLP with Transformers\";\n",
       "        color: white;\n",
       "        font-weight: bold;\n",
       "        text-transform: uppercase;\n",
       "        font-family: 'Lora',serif;\n",
       "        font-size:16pt;\n",
       "        margin-bottom:15px;\n",
       "        margin-top:15px;\n",
       "           \n",
       "}\n",
       "body > #header {\n",
       "    #background: #D15555;\n",
       "    background: linear-gradient(to bottom, indianred 0%, #fff 100%);\n",
       "    opacity: 0.8;\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       ".navbar-default .navbar-nav > li > a, #kernel_indicator {\n",
       "    color: white;\n",
       "    transition: all 0.25s;\n",
       "    font-size:10pt;\n",
       "    font-family: sans-serif;\n",
       "    font-weight:normal;\n",
       "}\n",
       ".navbar-default {\n",
       "    padding-left:100px;\n",
       "    background: none;\n",
       "    border: none;\n",
       "}\n",
       "\n",
       "\n",
       "body > menubar-container {\n",
       "    background-color: wheat;\n",
       "}\n",
       "#ipython_notebook img{                                                                                        \n",
       "    display:block; \n",
       "    \n",
       "    background: url(\"https://www.supportvectors.com/wp-content/uploads/2016/03/logo-poster-smaller.png\") no-repeat;\n",
       "    background-size: contain;\n",
       "   \n",
       "    padding-left: 600px;\n",
       "    padding-right: 100px;\n",
       "    \n",
       "    -moz-box-sizing: border-box;\n",
       "    box-sizing: border-box;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "body {\n",
       " #font-family:  'Literata', serif;\n",
       "    font-family:'Lora', san-serif;\n",
       "    text-align: justify;\n",
       "    font-weight: 400;\n",
       "    font-size: 12pt;\n",
       "}\n",
       "\n",
       "iframe{\n",
       "    width:100%;\n",
       "    min-height:600px;\n",
       "}\n",
       "\n",
       "h1, h2, h3, h4, h5, h6 {\n",
       "# font-family: 'Montserrat', sans-serif;\n",
       " font-family:'Lora', serif;\n",
       " font-weight: 200;\n",
       " text-transform: uppercase;\n",
       " color: #EC7063 ;\n",
       "}\n",
       "\n",
       "h2 {\n",
       "    color: #000080;\n",
       "}\n",
       "\n",
       ".checkpoint_status, .autosave_status {\n",
       "    color:wheat;\n",
       "}\n",
       "\n",
       "#notebook_name {\n",
       "    font-weight: 600;\n",
       "    font-size:20pt;\n",
       "    text-variant:uppercase;\n",
       "    color: wheat; \n",
       "    margin-right:20px;\n",
       "    margin-left:-500px;\n",
       "}\n",
       "#notebook_name:hover {\n",
       "background-color: salmon;\n",
       "}\n",
       "\n",
       "\n",
       ".dataframe { /* dataframe atau table */\n",
       "    background: white;\n",
       "    box-shadow: 0px 1px 2px #bbb;\n",
       "}\n",
       ".dataframe thead th, .dataframe tbody td {\n",
       "    text-align: center;\n",
       "    padding: 1em;\n",
       "}\n",
       "\n",
       ".checkpoint_status, .autosave_status {\n",
       "    color:wheat;\n",
       "}\n",
       "\n",
       ".output {\n",
       "    align-items: center;\n",
       "}\n",
       "\n",
       "div.cell {\n",
       "    transition: all 0.25s;\n",
       "    border: none;\n",
       "    position: relative;\n",
       "    top: 0;\n",
       "}\n",
       "div.cell.selected, div.cell.selected.jupyter-soft-selected {\n",
       "    border: none;\n",
       "    background: transparent;\n",
       "    box-shadow: 0 6px 18px #aaa;\n",
       "    z-index: 10;\n",
       "    top: -10px;\n",
       "}\n",
       ".CodeMirror pre, .CodeMirror-dialog, .CodeMirror-dialog .CodeMirror-search-field, .terminal-app .terminal {\n",
       "    font-family: 'Hack' , serif; \n",
       "    font-weight: 500;\n",
       "    font-size: 14pt;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "</style>    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "<center><img src=\"https://d4x5p7s4.rocketcdn.me/wp-content/uploads/2016/03/logo-poster-smaller.png\"/> </center>\n",
       "<div style=\"color:#aaa;font-size:8pt\">\n",
       "<hr/>\n",
       "&copy; SupportVectors. All rights reserved. <blockquote>This notebook is the intellectual property of SupportVectors, and part of its training material. \n",
       "Only the participants in SupportVectors workshops are allowed to study the notebooks for educational purposes currently, but is prohibited from copying or using it for any other purposes without written permission.\n",
       "\n",
       "<b> These notebooks are chapters and sections from Asif Qamar's textbook that he is writing on Data Science. So we request you to not circulate the material to others.</b>\n",
       " </blockquote>\n",
       " <hr/>\n",
       "</div>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run supportvectors-common.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85541636",
   "metadata": {},
   "source": [
    "## <img src=\"https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.png\" width=\"60px\">  Pretrained Transformers\n",
    "\n",
    "In this lab, we will delve into the pretrained transformers. \n",
    "\n",
    "In particular, we will continue our running example of sentiment analysis classification problem. We will see how to use a huggingface transformer\n",
    "\n",
    "### Transformers\n",
    "\n",
    "A pre-trained transformer, such as `bert` in the hugging-face repository exists as a head-less body: in other words, they produce a latent state embeddings. The weights of the transformer has been trained one some general task, such as MLM (masked language model): mask a few tokens in a sentence, and train the transformer to reconstruct the missing tokens as accurately as possible, from a vast corpus of documents. These weights form the **checkpoint** of the transformer model. Therefore, when we download and load a transformer from the hugging-face repository, we are actually loading the model with these particular trained checkpoint weights.\n",
    "\n",
    "Such a transformer body can be used for a variety of tasks by using these latent state embeddings as input to a head meant to perform a particular task.\n",
    "\n",
    "Let us say that we would like to create a text classifier for sentiment analysis -- i.e. classify each piece of text into the sentiment it represents. Then the pipeline we can build would look like this:\n",
    "\n",
    "<img src = \"classifier-pipeline.png\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ecc02f",
   "metadata": {},
   "source": [
    "First, we will need to tokenize the input text using a tokenizer. We covered this in a previous lab. The output of the tokenizer would be the input tokens to the transformer. The transformer will emit a hidden state embedding for each text. These embeddings become the input to the classifier network, which we can train using the gradient descent and backpropagation of gradients.\n",
    "\n",
    "Therefore, we typically would make the classifier itself a differentiable function, made of a few layers of feed forward network. Or in its most simple form, it could be single softmax layer.\n",
    "\n",
    "For the classification purposes, it is common to take only the transformer generated embedding of the `[CLS]` token as the input to the classifier, if one is using the `bert` transformer.\n",
    "\n",
    "<hr />\n",
    "<img src=\"nlp-with-transformers-book.png\"  width=\"150\" style=\"padding:20px;\" align=\"left\"> <b>Note</b>: Some of the code snippets below is inspired by, or directly taken from the book <a href=\"https://www.amazon.com/dp/1098136799\"> Natural Language Processing with Transformers, Revised Edition. </a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75b14a0",
   "metadata": {},
   "source": [
    "### Picking a sentiment analysis library\n",
    "\n",
    "Let us pick the pretrained model for sentiment analysis. There are many available on the huggingface repository, but we will pick one that gives a familiar rating on the Likert scale (from 1 to 5). It seems to have a reasonably good accuracy, reported as:\n",
    "\n",
    "<img src=\"images/sentiment-analysis-metrics.png\" width=400/>\n",
    "\n",
    "For a given input sequence, it produces the logit-vector with 5 elements, each element corresponding to a rating value from 1 to 5.\n",
    "\n",
    "Let us use a softmax classifier at the end to transform the logits to probabilities. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f548f88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c2b7a970394f2ab9b8876256d8b8c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/953 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bacab315bc424fa7b0dad16167ce8baf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/669M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b3665b",
   "metadata": {},
   "source": [
    "<!--\n",
    "\n",
    "`Distilbert` is a much smaller model, that approximates the accuracy the much larger `BERT` model. Since it is much easier to play with for inferences, especially when working on laptops without gpu/tpu acceleration support, we will use it for this lab.\n",
    "\n",
    "**Note**: Considering that many of us do not have powerful laptops with tensor accelerators, we have not moved the model to the \"cuda\" device. However, if you do have that available, strongly consider using that with the syntax:\n",
    "\n",
    "```\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device\n",
    "```\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f7b941",
   "metadata": {},
   "source": [
    "Let us explore what the output hidden state embeddings of this transformer looks like; first we will take a text and tokenize it. Then we will input it to the transformer, and look at the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4947d751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd78c22d46b427185e72ec82aa81415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/39.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "636c0ad032be4cc9a5bf09088f686e67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8fcd5e2c62240c1be967ff0bb874d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,   143, 21973, 10108, 25209, 10127,   143, 27318, 10139, 15765,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "The shape of the input is torch.Size([1, 11])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"nlptown/bert-base-multilingual-uncased-sentiment\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "text = 'A thing of beauty is a joy for ever'\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "print(inputs)\n",
    "print(f\"The shape of the input is {inputs['input_ids'].size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d55a9ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids', 'token_type_ids', 'attention_mask']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_input_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db52289",
   "metadata": {},
   "source": [
    "In what follows, for simplicity, we will skip the step of loading it into the gpu; however, augment the code to run it on the gpu. Hint: use `.to(device)` on the values, before passing it to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc6286e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-2.2633, -2.5239, -0.9028,  1.4483,  3.4063]]), hidden_states=None, attentions=None)\n",
      "The logits are: [-2.2632933 -2.5239275 -0.9028079  1.4482905  3.406254 ]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    print(outputs)\n",
    "    \n",
    "logits = outputs.logits\n",
    "print (f'The logits are: {logits[0].numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9875b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0030, 0.0023, 0.0116, 0.1216, 0.8615]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.functional import softmax\n",
    "predictions = softmax(logits, dim=-1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e62d0c8",
   "metadata": {},
   "source": [
    "Let us display it in a more intuitive manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35efc24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 1  Probability: 0.00\n",
      "Rating: 2  Probability: 0.00\n",
      "Rating: 3  Probability: 0.01\n",
      "Rating: 4  Probability: 0.12\n",
      "Rating: 5  Probability: 0.86\n"
     ]
    }
   ],
   "source": [
    "ratings = [1,2,3,4,5]\n",
    "for rating, probability in zip(ratings, predictions[0]):\n",
    "    print (f'Rating: {rating}  Probability: {probability.numpy():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0163ce8",
   "metadata": {},
   "source": [
    "In other words, if the text `A thing of beauty is a joy forever` were a comment on a product, the sentiment it expresses is very positive.\n",
    "\n",
    "\n",
    "# Passing a batch of input\n",
    "\n",
    "Needless to say, we could have passed a small batch of texts as inputs for sentiment analysis. The process remains the same, with only minor and expected changes. Let us see that example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b816d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-2.1803, -2.4672, -0.8363,  1.3856,  3.2928],\n",
      "        [ 4.5518,  2.7818, -0.1818, -3.0668, -3.2394],\n",
      "        [-2.7100, -0.2763,  2.2295,  2.0550, -1.1312]]), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[3.5822e-03, 2.6888e-03, 1.3736e-02, 1.2672e-01, 8.5327e-01],\n",
       "        [8.4743e-01, 1.4435e-01, 7.4532e-03, 4.1628e-04, 3.5030e-04],\n",
       "        [3.6457e-03, 4.1567e-02, 5.0934e-01, 4.2776e-01, 1.7680e-02]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = ['A thing of beauty is a joy forever', \n",
    "         'I would really not recommend this horrible shoe; it hurts on long walks!',\n",
    "         'It is quite satisfactory, but not exceptionally good'\n",
    "        ]\n",
    "inputs = tokenizer(texts, return_tensors='pt', padding=True)\n",
    "import torch\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    print(outputs)\n",
    "    \n",
    "logits = outputs.logits\n",
    "predictions = softmax(logits, dim=-1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668b2ac9",
   "metadata": {},
   "source": [
    "Let us display it an a more readable, user-friendly manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6da9eaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A thing of beauty is a joy forever                                                                   tensor([0.0036, 0.0027, 0.0137, 0.1267, 0.8533])\n",
      "I would really not recommend this horrible shoe; it hurts on long walks!                             tensor([8.4743e-01, 1.4435e-01, 7.4532e-03, 4.1628e-04, 3.5030e-04])\n",
      "It is quite satisfactory, but not exceptionally good                                                 tensor([0.0036, 0.0416, 0.5093, 0.4278, 0.0177])\n"
     ]
    }
   ],
   "source": [
    "for text, prediction in zip (texts, predictions):\n",
    "    print (f'{text:<100} {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "462fe799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A thing of beauty is a joy forever</td>\n",
       "      <td>*****</td>\n",
       "      <td>0.853274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I would really not recommend this horrible sho...</td>\n",
       "      <td>*</td>\n",
       "      <td>0.847430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is quite satisfactory, but not exceptionall...</td>\n",
       "      <td>***</td>\n",
       "      <td>0.509343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Rating  Probability\n",
       "0                 A thing of beauty is a joy forever  *****     0.853274\n",
       "1  I would really not recommend this horrible sho...      *     0.847430\n",
       "2  It is quite satisfactory, but not exceptionall...    ***     0.509343"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [(1+ np.argmax(prediction.numpy()), np.max(prediction.numpy())) for prediction in predictions]\n",
    "\n",
    "ratings = []\n",
    "probs = []\n",
    "\n",
    "for rating, prob in results:\n",
    "    ratings.append('*'*rating)\n",
    "    probs.append(prob)\n",
    "\n",
    "data = pd.DataFrame(data={'Text': texts, 'Rating': ratings, 'Probability': probs})\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761efddc",
   "metadata": {},
   "source": [
    "## What did we learn?\n",
    "\n",
    "In this lab, we learned to build a complete text classifier for sentiment analysis. To do this, we concatenated the following pieces into a hand-constructed pipeline:\n",
    "\n",
    "* a pretrained tokenizer\n",
    "* a pretrained transformer\n",
    "* finally, a softmax classifier\n",
    "\n",
    "This gives us an insight into what the `pipeline()` from the previous labs were doing. Let us revisit the simpler way of directly using the `pipeline()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0995332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '5 stars', 'score': 0.8532741069793701},\n",
       " {'label': '1 star', 'score': 0.8474298119544983},\n",
       " {'label': '3 stars', 'score': 0.5093432068824768}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "checkpoint = 'nlptown/bert-base-multilingual-uncased-sentiment'\n",
    "sentiment_classifier = pipeline (task='sentiment-analysis', \n",
    "                                 tokenizer=checkpoint, # not necessary to mention, since it can be inferred\n",
    "                                 model=checkpoint)\n",
    "sentiment_classifier(texts)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
