{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa2f8212",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-08T08:19:49.294037Z",
     "start_time": "2023-04-08T08:19:47.533476Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<!-- Many of the styles here are inspired by: \n",
       "    https://towardsdatascience.com/10-practical-tips-you-need-to-know-to-personalize-jupyter-notebook-fbd202777e20 \n",
       "       \n",
       "    \n",
       "    On the author's local machine, these exist in the custom.css file. However, in order to keep uniform look and feel, \n",
       "    and at the request of participants, I have added it to this common import-file here.\n",
       "\n",
       "    -->\n",
       "\n",
       "<link href=\"https://fonts.googleapis.com/css?family=Lora:400,700|Montserrat:300\" rel=\"stylesheet\">\n",
       "\n",
       "<link href=\"https://fonts.googleapis.com/css2?family=Crimson+Pro&family=Literata&display=swap\" rel=\"stylesheet\">\n",
       "<style>\n",
       "\n",
       "\n",
       "#ipython_notebook::before{\n",
       " content:\"NLP with Transformers\";\n",
       "        color: white;\n",
       "        font-weight: bold;\n",
       "        text-transform: uppercase;\n",
       "        font-family: 'Lora',serif;\n",
       "        font-size:16pt;\n",
       "        margin-bottom:15px;\n",
       "        margin-top:15px;\n",
       "           \n",
       "}\n",
       "body > #header {\n",
       "    #background: #D15555;\n",
       "    background: linear-gradient(to bottom, indianred 0%, #fff 100%);\n",
       "    opacity: 0.8;\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       ".navbar-default .navbar-nav > li > a, #kernel_indicator {\n",
       "    color: white;\n",
       "    transition: all 0.25s;\n",
       "    font-size:10pt;\n",
       "    font-family: sans-serif;\n",
       "    font-weight:normal;\n",
       "}\n",
       ".navbar-default {\n",
       "    padding-left:100px;\n",
       "    background: none;\n",
       "    border: none;\n",
       "}\n",
       "\n",
       "\n",
       "body > menubar-container {\n",
       "    background-color: wheat;\n",
       "}\n",
       "#ipython_notebook img{                                                                                        \n",
       "    display:block; \n",
       "    \n",
       "    background: url(\"https://www.supportvectors.com/wp-content/uploads/2016/03/logo-poster-smaller.png\") no-repeat;\n",
       "    background-size: contain;\n",
       "   \n",
       "    padding-left: 600px;\n",
       "    padding-right: 100px;\n",
       "    \n",
       "    -moz-box-sizing: border-box;\n",
       "    box-sizing: border-box;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "body {\n",
       " #font-family:  'Literata', serif;\n",
       "    font-family:'Lora', san-serif;\n",
       "    text-align: justify;\n",
       "    font-weight: 400;\n",
       "    font-size: 12pt;\n",
       "}\n",
       "\n",
       "iframe{\n",
       "    width:100%;\n",
       "    min-height:600px;\n",
       "}\n",
       "\n",
       "h1, h2, h3, h4, h5, h6 {\n",
       "# font-family: 'Montserrat', sans-serif;\n",
       " font-family:'Lora', serif;\n",
       " font-weight: 200;\n",
       " text-transform: uppercase;\n",
       " color: #EC7063 ;\n",
       "}\n",
       "\n",
       "h2 {\n",
       "    color: #000080;\n",
       "}\n",
       "\n",
       ".checkpoint_status, .autosave_status {\n",
       "    color:wheat;\n",
       "}\n",
       "\n",
       "#notebook_name {\n",
       "    font-weight: 600;\n",
       "    font-size:20pt;\n",
       "    text-variant:uppercase;\n",
       "    color: wheat; \n",
       "    margin-right:20px;\n",
       "    margin-left:-500px;\n",
       "}\n",
       "#notebook_name:hover {\n",
       "background-color: salmon;\n",
       "}\n",
       "\n",
       "\n",
       ".dataframe { /* dataframe atau table */\n",
       "    background: white;\n",
       "    box-shadow: 0px 1px 2px #bbb;\n",
       "}\n",
       ".dataframe thead th, .dataframe tbody td {\n",
       "    text-align: center;\n",
       "    padding: 1em;\n",
       "}\n",
       "\n",
       ".checkpoint_status, .autosave_status {\n",
       "    color:wheat;\n",
       "}\n",
       "\n",
       ".output {\n",
       "    align-items: center;\n",
       "}\n",
       "\n",
       "div.cell {\n",
       "    transition: all 0.25s;\n",
       "    border: none;\n",
       "    position: relative;\n",
       "    top: 0;\n",
       "}\n",
       "div.cell.selected, div.cell.selected.jupyter-soft-selected {\n",
       "    border: none;\n",
       "    background: transparent;\n",
       "    box-shadow: 0 6px 18px #aaa;\n",
       "    z-index: 10;\n",
       "    top: -10px;\n",
       "}\n",
       ".CodeMirror pre, .CodeMirror-dialog, .CodeMirror-dialog .CodeMirror-search-field, .terminal-app .terminal {\n",
       "    font-family: 'Hack' , serif; \n",
       "    font-weight: 500;\n",
       "    font-size: 14pt;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "</style>    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "<center><img src=\"https://d4x5p7s4.rocketcdn.me/wp-content/uploads/2016/03/logo-poster-smaller.png\"/> </center>\n",
       "<div style=\"color:#aaa;font-size:8pt\">\n",
       "<hr/>\n",
       "&copy; SupportVectors. All rights reserved. <blockquote>This notebook is the intellectual property of SupportVectors, and part of its training material. \n",
       "Only the participants in SupportVectors workshops are allowed to study the notebooks for educational purposes currently, but is prohibited from copying or using it for any other purposes without written permission.\n",
       "\n",
       "<b> These notebooks are chapters and sections from Asif Qamar's textbook that he is writing on Data Science. So we request you to not circulate the material to others.</b>\n",
       " </blockquote>\n",
       " <hr/>\n",
       "</div>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run supportvectors-common.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972325b8",
   "metadata": {},
   "source": [
    "# LangChain Tools\n",
    "\n",
    "As we learned in a previous lab, agents in `langchain` create dynamic chains based on the context and user inputs, using the appropriate tools and large language models.\n",
    "\n",
    "### Learning goal\n",
    "\n",
    "In this lab, we will develop more fluency with the some of the tools that are available as part of the `langchain` ecosystem. Later on, in a subsequent lab, we will learn to create our own **custom tools**.\n",
    "\n",
    "Let us begin by installing a few libraries that we will need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f68b08e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: uncomment this only if these libraries are not already installed.\n",
    "\n",
    "#!pip install arxiv\n",
    "#!pip install wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc25b9ff",
   "metadata": {},
   "source": [
    "Then, let us import the components we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3785d1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate, FewShotPromptTemplate\n",
    "from langchain.utilities import ArxivAPIWrapper\n",
    "from langchain.utilities import WikipediaAPIWrapper\n",
    "from langchain import LLMMathChain, SerpAPIWrapper\n",
    "from langchain.agents import AgentType, Tool, initialize_agent, tool\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.agents import load_tools\n",
    "from langchain.chains import LLMChain\n",
    "from IPython.display import Markdown, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b47ac34",
   "metadata": {},
   "source": [
    "## List of useful tools\n",
    "\n",
    "`langchain` comes with many tools that help with common tasks. To see the full list, visit the website: https://python.langchain.com/en/latest/modules/agents/tools.html\n",
    "\n",
    "Let us browse through it and become familiar with the rich ecosystem of tools already available. Furthermore, we can easily create our own custom tools with relative ease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba13a86",
   "metadata": {},
   "source": [
    "## The search tool\n",
    "Let us play with the search tool, and see how it works. First we will invoke it directly. Later, we will make it a part of a `langchain`, and use it with an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75926117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'south Fremont'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = SerpAPIWrapper()\n",
    "search.run ('Where is SupportVectors AI Lab located?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f60447",
   "metadata": {},
   "source": [
    "Now, let us use it with a chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4f5f9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_names = ['serpapi']\n",
    "tools = load_tools(tool_names)\n",
    "llm   = OpenAI(temperature=0.9) \n",
    "agent = initialize_agent(\n",
    "                        tools   = tools,\n",
    "                        llm     = llm,\n",
    "                        agent   = AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "                        verbose = True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "908fcc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out the climate of SupportVectors AI lab's city\n",
      "Action: Search\n",
      "Action Input: Climate of SupportVectors AI lab's city\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['Our workshop environment encourages a creative, fun, and comfortable atmosphere. ... a Big-data cluster lab, with GPU-accelerated servers ...']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m SupportVectors AI lab is located in Hong Kong\n",
      "Action: Search\n",
      "Action Input: Weather in Hong Kong\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'type': 'weather_result', 'temperature': '77', 'unit': 'Fahrenheit', 'precipitation': '16%', 'humidity': '93%', 'wind': '7 mph', 'location': 'Hong Kong', 'date': 'Tuesday 2:00 AM', 'weather': 'Mostly cloudy'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer:\n",
      "\n",
      "<blockquote><h4>Scorcher in the Skyline </h4>\n",
      "\n",
      "The climate in SupportVectors AI lab’s city, Hong Kong, is mostly cloudy with temperatures around 77°F (25°C), 16% precipitation, 93% humidity, and wind speeds of 7 mph.\n",
      "\n",
      "<h4>Hikes</h4>\n",
      "\n",
      "1. Victoria Peak – Get breathtaking views of the skyline and sea while trekking up almost 2 km of winding paths.\n",
      "\n",
      "2. Lantau Island – Glimpse beautiful temples and monasteries, swaying bamboo forests, and the silver lake Tai O.\n",
      "\n",
      "3. Mui Wo – Explore the beaches and nature trails around this “Back Garden of Hong Kong.”\n",
      "\n",
      "4. Sai Kung – Take in the striking natural beauty of acres of untouched coastline.\n",
      "\n",
      "5. High Junk Peak – Enjoy some of the city’s best views of the nearby islands from the top of this iconic hill.\n",
      "\n",
      "</blockquote>\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<blockquote><h4>Scorcher in the Skyline </h4>\n",
       "\n",
       "The climate in SupportVectors AI lab’s city, Hong Kong, is mostly cloudy with temperatures around 77°F (25°C), 16% precipitation, 93% humidity, and wind speeds of 7 mph.\n",
       "\n",
       "<h4>Hikes</h4>\n",
       "\n",
       "1. Victoria Peak – Get breathtaking views of the skyline and sea while trekking up almost 2 km of winding paths.\n",
       "\n",
       "2. Lantau Island – Glimpse beautiful temples and monasteries, swaying bamboo forests, and the silver lake Tai O.\n",
       "\n",
       "3. Mui Wo – Explore the beaches and nature trails around this “Back Garden of Hong Kong.”\n",
       "\n",
       "4. Sai Kung – Take in the striking natural beauty of acres of untouched coastline.\n",
       "\n",
       "5. High Junk Peak – Enjoy some of the city’s best views of the nearby islands from the top of this iconic hill.\n",
       "\n",
       "</blockquote>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "What is the climate like in the city where SupportVectors AI lab is located? \n",
    "\n",
    "Describe the weather with a witty and catchy title, in the format.\n",
    "\n",
    "<blockquote><h4>[Weather Title] </h4>\n",
    "\n",
    "\n",
    "[Weather]\n",
    "\n",
    "Then enumerate and describe 5 pleasant hikes in that neighborhood in the today's weather.\n",
    "\n",
    "\n",
    "<h4> Hikes</h4>\n",
    "\n",
    "[Hikes]\n",
    "\n",
    "</blockquote>\n",
    "\"\"\"\n",
    "\n",
    "result = agent.run (query)\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77a254b",
   "metadata": {},
   "source": [
    "### Arxiv\n",
    "\n",
    "Let us begin by playing with another utility, to search only in the arxiv repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc50763f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div class=\"alert-box alert-info\" style=\"padding-top:30px\">\n",
    "\n",
    "<h4> What is Arxiv?</h4>\n",
    "  \n",
    "    \n",
    "> Arxiv is one of the largest repositories of research work. Most of the new developments in our field of AI show up first as a pre-prints, and only much later some of them make their way into research journals and conference proceedings. As such, it has become the *de-facto* watering hole for researchers to go to, in search of new developments.\n",
    "> \n",
    "> We will use the `arxiv` library, and the `langchain.utilities.ArxivAPIWrapper` class to illustrate the use of this tool.\n",
    "    \n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6b60d0",
   "metadata": {},
   "source": [
    "We will begin by instantiating a `langchain` api-wrapper around the `arxiv` library. Then we will run it to see it retrieve pertinent pre-prints for us.\n",
    "\n",
    "We will consider an old paper in high-energy physics that the instructor co-authored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a5597ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Published: 1997-07-14\n",
      "Title: Hyperfine Splitting of Low-Lying Heavy Baryons\n",
      "Authors: M. Harada, A. Qamar, F. Sannino, J. Schechter, H. Weigel\n",
      "Summary: We calculate the next-to-leading order contribution to the masses of the\n",
      "heavy baryons in the bound state approach for baryons containing a heavy quark.\n",
      "These $1/N_C$ corrections arise when states of good spin and isospin are\n",
      "generated from the background soliton of the light meson fields. Our study is\n",
      "motivated by the previously established result that light vector meson fields\n",
      "are required for this soliton in order to reasonably describe the spectrum of\n",
      "both the light and the heavy baryons. We note that the inclusion of light\n",
      "vector mesons significantly improves the agreement of the predicted hyperfine\n",
      "splitting with experiment. A number of aspects of this somewhat complicated\n",
      "calculation are discussed in detail.\n"
     ]
    }
   ],
   "source": [
    "query = 'hep-ph/9703234'\n",
    "arxiv = ArxivAPIWrapper()\n",
    "docs = arxiv.run(query)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66b216b",
   "metadata": {},
   "source": [
    "Let us now illustrate its use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f1cd5f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Tool\nargs_schema\n  subclass of BaseModel expected (type=type_error.subclass; expected_class=BaseModel)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mArxivInput\u001b[39;00m(BaseModel):\n\u001b[1;32m      4\u001b[0m     preprint: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m Field ()\n\u001b[0;32m----> 6\u001b[0m tool \u001b[38;5;241m=\u001b[39m \u001b[43mTool\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43marxiv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43marxiv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43margs_schema\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mArxivInput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSearch the arxiv pre-print repository\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain/tools/base.py:539\u001b[0m, in \u001b[0;36mTool.__init__\u001b[0;34m(self, name, func, description, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m, func: Optional[Callable], description: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m    537\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    538\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initialize tool.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 539\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for Tool\nargs_schema\n  subclass of BaseModel expected (type=type_error.subclass; expected_class=BaseModel)"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ArxivInput(BaseModel):\n",
    "    preprint: str = Field ()\n",
    "\n",
    "tool = Tool (\n",
    "            name         = 'arxiv',\n",
    "            func         = arxiv.run,\n",
    "            args_schema  = ArxivInput,\n",
    "            description  = 'Search the arxiv pre-print repository')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9a1fc70",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'is_single_input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m tools \u001b[38;5;241m=\u001b[39m [tool]\n\u001b[1;32m      2\u001b[0m llm   \u001b[38;5;241m=\u001b[39m OpenAI(temperature \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43minitialize_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                        \u001b[49m\u001b[43magent\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mAgentType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZERO_SHOT_REACT_DESCRIPTION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m                         \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain/agents/initialize.py:57\u001b[0m, in \u001b[0;36minitialize_agent\u001b[0;34m(tools, llm, agent, callback_manager, agent_path, agent_kwargs, tags, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m     agent_cls \u001b[38;5;241m=\u001b[39m AGENT_TO_CLASS[agent]\n\u001b[1;32m     56\u001b[0m     agent_kwargs \u001b[38;5;241m=\u001b[39m agent_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m---> 57\u001b[0m     agent_obj \u001b[38;5;241m=\u001b[39m \u001b[43magent_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_llm_and_tools\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43magent_kwargs\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m agent_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     agent_obj \u001b[38;5;241m=\u001b[39m load_agent(\n\u001b[1;32m     62\u001b[0m         agent_path, llm\u001b[38;5;241m=\u001b[39mllm, tools\u001b[38;5;241m=\u001b[39mtools, callback_manager\u001b[38;5;241m=\u001b[39mcallback_manager\n\u001b[1;32m     63\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain/agents/mrkl/base.py:101\u001b[0m, in \u001b[0;36mZeroShotAgent.from_llm_and_tools\u001b[0;34m(cls, llm, tools, callback_manager, output_parser, prefix, suffix, format_instructions, input_variables, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_llm_and_tools\u001b[39m(\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Agent:\n\u001b[1;32m    100\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct an agent from an LLM and tools.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_prompt(\n\u001b[1;32m    103\u001b[0m         tools,\n\u001b[1;32m    104\u001b[0m         prefix\u001b[38;5;241m=\u001b[39mprefix,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m         input_variables\u001b[38;5;241m=\u001b[39minput_variables,\n\u001b[1;32m    108\u001b[0m     )\n\u001b[1;32m    109\u001b[0m     llm_chain \u001b[38;5;241m=\u001b[39m LLMChain(\n\u001b[1;32m    110\u001b[0m         llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[1;32m    111\u001b[0m         prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m    112\u001b[0m         callback_manager\u001b[38;5;241m=\u001b[39mcallback_manager,\n\u001b[1;32m    113\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain/agents/mrkl/base.py:125\u001b[0m, in \u001b[0;36mZeroShotAgent._validate_tools\u001b[0;34m(cls, tools)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_tools\u001b[39m(\u001b[38;5;28mcls\u001b[39m, tools: Sequence[BaseTool]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     \u001b[43mvalidate_tools_single_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tools) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    128\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot no tools for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. At least one tool must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    129\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain/agents/utils.py:9\u001b[0m, in \u001b[0;36mvalidate_tools_single_input\u001b[0;34m(class_name, tools)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Validate tools for single input.\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m tools:\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mtool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_single_input\u001b[49m:\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     11\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not support multi-input tool \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtool\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m         )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'is_single_input'"
     ]
    }
   ],
   "source": [
    "tools = [tool]\n",
    "llm   = OpenAI(temperature = 0.0)\n",
    "agent = initialize_agent(\n",
    "                        tools   = tools,\n",
    "                        llm     = llm,\n",
    "                        agent   = AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "                        verbose = True\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127d22bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Search for papers dealing with \"Attention is all you need\". Show the first 5 results.'\n",
    "results = agent.run(query)\n",
    "print (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf99a0b",
   "metadata": {},
   "source": [
    "### Homework\n",
    "\n",
    "Convert the bash command tool below to a custom tool (even if one exists for it in the `langchain` ecosystem), and run it to find all files whose names contain the sub-string 'langchain'.\n",
    "\n",
    "We show the basics of using the utility below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42399462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import BashProcess\n",
    "bash = BashProcess()\n",
    "print (bash.run('ls -l'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972be26b",
   "metadata": {},
   "source": [
    "## What we have learned?\n",
    "\n",
    "In this lab, we learned about:\n",
    "\n",
    "* we have learned about the ecosystem of available tools\n",
    "* how we can use the tools to good effect in creating useful language chains\n",
    "* became familiar with `arxiv` and `wikipedia` libraries, and used them as tools\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
