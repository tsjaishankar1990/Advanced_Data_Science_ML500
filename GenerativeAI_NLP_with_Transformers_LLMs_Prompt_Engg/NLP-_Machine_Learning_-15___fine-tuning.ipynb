{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa2f8212",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-08T08:19:49.294037Z",
     "start_time": "2023-04-08T08:19:47.533476Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<!-- Many of the styles here are inspired by: \n",
       "    https://towardsdatascience.com/10-practical-tips-you-need-to-know-to-personalize-jupyter-notebook-fbd202777e20 \n",
       "       \n",
       "    \n",
       "    On the author's local machine, these exist in the custom.css file. However, in order to keep uniform look and feel, \n",
       "    and at the request of participants, I have added it to this common import-file here.\n",
       "\n",
       "    -->\n",
       "\n",
       "<link href=\"https://fonts.googleapis.com/css?family=Lora:400,700|Montserrat:300\" rel=\"stylesheet\">\n",
       "\n",
       "<link href=\"https://fonts.googleapis.com/css2?family=Crimson+Pro&family=Literata&display=swap\" rel=\"stylesheet\">\n",
       "<style>\n",
       "\n",
       "\n",
       "#ipython_notebook::before{\n",
       " content:\"NLP with Transformers\";\n",
       "        color: white;\n",
       "        font-weight: bold;\n",
       "        text-transform: uppercase;\n",
       "        font-family: 'Lora',serif;\n",
       "        font-size:16pt;\n",
       "        margin-bottom:15px;\n",
       "        margin-top:15px;\n",
       "           \n",
       "}\n",
       "body > #header {\n",
       "    #background: #D15555;\n",
       "    background: linear-gradient(to bottom, indianred 0%, #fff 100%);\n",
       "    opacity: 0.8;\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       ".navbar-default .navbar-nav > li > a, #kernel_indicator {\n",
       "    color: white;\n",
       "    transition: all 0.25s;\n",
       "    font-size:10pt;\n",
       "    font-family: sans-serif;\n",
       "    font-weight:normal;\n",
       "}\n",
       ".navbar-default {\n",
       "    padding-left:100px;\n",
       "    background: none;\n",
       "    border: none;\n",
       "}\n",
       "\n",
       "\n",
       "body > menubar-container {\n",
       "    background-color: wheat;\n",
       "}\n",
       "#ipython_notebook img{                                                                                        \n",
       "    display:block; \n",
       "    \n",
       "    background: url(\"https://www.supportvectors.com/wp-content/uploads/2016/03/logo-poster-smaller.png\") no-repeat;\n",
       "    background-size: contain;\n",
       "   \n",
       "    padding-left: 600px;\n",
       "    padding-right: 100px;\n",
       "    \n",
       "    -moz-box-sizing: border-box;\n",
       "    box-sizing: border-box;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "body {\n",
       " #font-family:  'Literata', serif;\n",
       "    font-family:'Lora', san-serif;\n",
       "    text-align: justify;\n",
       "    font-weight: 400;\n",
       "    font-size: 12pt;\n",
       "}\n",
       "\n",
       "iframe{\n",
       "    width:100%;\n",
       "    min-height:600px;\n",
       "}\n",
       "\n",
       "h1, h2, h3, h4, h5, h6 {\n",
       "# font-family: 'Montserrat', sans-serif;\n",
       " font-family:'Lora', serif;\n",
       " font-weight: 200;\n",
       " text-transform: uppercase;\n",
       " color: #EC7063 ;\n",
       "}\n",
       "\n",
       "h2 {\n",
       "    color: #000080;\n",
       "}\n",
       "\n",
       ".checkpoint_status, .autosave_status {\n",
       "    color:wheat;\n",
       "}\n",
       "\n",
       "#notebook_name {\n",
       "    font-weight: 600;\n",
       "    font-size:20pt;\n",
       "    text-variant:uppercase;\n",
       "    color: wheat; \n",
       "    margin-right:20px;\n",
       "    margin-left:-500px;\n",
       "}\n",
       "#notebook_name:hover {\n",
       "background-color: salmon;\n",
       "}\n",
       "\n",
       "\n",
       ".dataframe { /* dataframe atau table */\n",
       "    background: white;\n",
       "    box-shadow: 0px 1px 2px #bbb;\n",
       "}\n",
       ".dataframe thead th, .dataframe tbody td {\n",
       "    text-align: center;\n",
       "    padding: 1em;\n",
       "}\n",
       "\n",
       ".checkpoint_status, .autosave_status {\n",
       "    color:wheat;\n",
       "}\n",
       "\n",
       ".output {\n",
       "    align-items: center;\n",
       "}\n",
       "\n",
       "div.cell {\n",
       "    transition: all 0.25s;\n",
       "    border: none;\n",
       "    position: relative;\n",
       "    top: 0;\n",
       "}\n",
       "div.cell.selected, div.cell.selected.jupyter-soft-selected {\n",
       "    border: none;\n",
       "    background: transparent;\n",
       "    box-shadow: 0 6px 18px #aaa;\n",
       "    z-index: 10;\n",
       "    top: -10px;\n",
       "}\n",
       ".CodeMirror pre, .CodeMirror-dialog, .CodeMirror-dialog .CodeMirror-search-field, .terminal-app .terminal {\n",
       "    font-family: 'Hack' , serif; \n",
       "    font-weight: 500;\n",
       "    font-size: 14pt;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "</style>    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "<div style=\"color:#aaa;font-size:8pt\">\n",
       "<hr/>\n",
       "\n",
       " </blockquote>\n",
       " <hr/>\n",
       "</div>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run supportvectors-common.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85541636",
   "metadata": {},
   "source": [
    "## <img src=\"https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.png\" width=\"60px\">  Fine tuning the Transformers\n",
    "\n",
    "Sometimes, a pretrained model may not exactly fit our task, and so the inference performance will leave scope for improvement. At such a time, if additional task-specific training data is available, we can fine tune the models. This is the second part of the transfer learning journey: take a pretrained model, and fine tune it by further training it on a task-specific dataset for a few epochs.\n",
    "\n",
    "It is worth noting that, for pre-training the models, the process is oftentimes self-supervised. In other words, labeled data is not necessary. For example, we can pre-train the masked language models simply by taking a vast corpus of documents, decompose them into sentences. Each sentence then becomes the datum for pre-training as an `<input, label>` pair, simply by randomly masking a few words, and treating the masked words as labels.\n",
    "\n",
    "Therefore, pre-training is done with:\n",
    "\n",
    "* vast quantities of data, and consequently large number of training steps over the mini-batches\n",
    "* using unlabeled data most of the time (i.e., as self-supervised learning), by cleverly extracting `<input, label>` pairs as training data instances from the data\n",
    "\n",
    "On the other hand, the fine-tuning of the models involves:\n",
    "\n",
    "* availability of labeled data for the specific task\n",
    "* the dataset sizes are **generally not needed to be big -- indeed, small datasets mostly suffice.**\n",
    "* running a much shorter training cycle, with a few epochs over the task-specific data\n",
    "* **far less hardware resource**\n",
    "* because of the above, two far less model (fine-tuning) training time\n",
    "* and causes a **far smaller carbon footprint or environmental impact**!\n",
    "\n",
    "\n",
    "Therefore, wherever feasible, we should resort to transfer learning, and therefore, fine-tuning of the pretrained models as our preferred approach.\n",
    "\n",
    "The `Huggingface` core libraries makes it rather easily to fine-tune the pretrained models. For this, we will use the following libraries:\n",
    "\n",
    "* `datasets` the library that makes it easy to load and use a vast number of publicly available datasets, many of which belong to well-known benchmarks. For example, in this lab we will use the `mrpc` dataset from the `GLUE` benchmark for nlp tasks.\n",
    "\n",
    "* `transformers` the main library of models and tokenizers, etc.\n",
    "\n",
    "* `evaluate` an excellent library to evaluate the inference performance of the trained models, and to compare performances across models.\n",
    "\n",
    "#### Installation\n",
    "\n",
    "Quite likey, by now you have installed each of the below library on your workstation. Otherwise, uncomment the below cell and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aa9ef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Uncomment this only if needed.\n",
    "#\n",
    "#!pip install datasets transformers evaluate --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1389b0",
   "metadata": {},
   "source": [
    "### Load the `mrpc` dataset\n",
    "This dataset contains sentence-pairs; the label specifies whether the second sentence is the paraphrase of the first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9570317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (/home/asif/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52759c33c8d74afd9cdda290b31906c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f553de1f",
   "metadata": {},
   "source": [
    "Let us explore it a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dc311ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576dc37b",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "The `raw_datasets` comprises of three datasets (`train`, `validation`, `test`), stored in a dictionary `DatasetDict` object. This is rather convenient, since it has already been split into the train-validate-test subsets.\n",
    "\n",
    "We also note that there only `3668 + 408 + 1725 = 5801` instances of data. This is a considerably smaller dataset, and only `3668` for fine-tuning a pre-trained model.\n",
    "\n",
    "Also note that the input $\\mathbf{X}$ is derived from a pair of sentences `<sentence1, sentence2>`. The ouput is, of-course, marked as the `label`.\n",
    "\n",
    "\n",
    "### Load pretrained models\n",
    "\n",
    "Let us now load the pretrained tokenizer and transformer models. This is nearly identical to what we did in the previous labs.\n",
    "\n",
    "There is however a subtlety when using the tokenizer. So far, we have been passing only one sentence to the tokenizer. But here we have pairs of sentences in this dataset. Fortunately, the tokenizers for `BERT` do accept pairs of sentences.\n",
    "\n",
    "Recall that in the original exploration of the `BERT` research paper, we saw how the model was pre-trained using inputs as  sentence pairs.\n",
    "\n",
    "#### Data Collator\n",
    "\n",
    "Observe a new animal we introduced to our zoo here, the `DataCollatorWithPadding`.\n",
    "\n",
    "Data collators are responsible for forming (mini-) batches of the datasets. They preserve the form of the original data, but may perform some post-processing as needed.\n",
    "\n",
    "For example, in our task, the sentences may be of variable length. So the `DataCollatorWithPadding` will pad each of the tokenized sequences in a mini-batch so that its length is that of the large sequence present in that mini-batch.\n",
    "\n",
    "<img src=\"images/data-prep-for-fine-tuning.jpeg\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eccbf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/asif/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-8fa0ec02105bbfdd.arrow\n",
      "Loading cached processed dataset at /home/asif/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-32460ce84408f1c7.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d0b86e",
   "metadata": {},
   "source": [
    "#### Load the pretrained model checkpoint\n",
    "\n",
    "Next we load a pre-trained model checkpoint, that is specific to the sequence classification task.\n",
    "\n",
    "> The classification task here: inferring whether the `sentence2` is a **paraphrasing** of the `sentence1` for a given input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be9ce58f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88b4d39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 10:04:43] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 10:04:43] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 10:04:43] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 10:04:43] [setup] CPU Tracking...\n",
      "[codecarbon INFO @ 10:04:43] Tracking Intel CPU via RAPL interface\n",
      "[codecarbon INFO @ 10:04:44] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 10:04:44]   Platform system: Linux-5.19.0-38-generic-x86_64-with-glibc2.35\n",
      "[codecarbon INFO @ 10:04:44]   Python version: 3.10.9\n",
      "[codecarbon INFO @ 10:04:44]   Available RAM : 125.570 GB\n",
      "[codecarbon INFO @ 10:04:44]   CPU count: 32\n",
      "[codecarbon INFO @ 10:04:44]   CPU model: 13th Gen Intel(R) Core(TM) i9-13900K\n",
      "[codecarbon INFO @ 10:04:44]   GPU count: 1\n",
      "[codecarbon INFO @ 10:04:44]   GPU model: 1 x NVIDIA GeForce RTX 4090\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1377' max='1377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1377/1377 00:33, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.489500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.248200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 10:05:02] Energy consumed for RAM : 0.000196 kWh. RAM Power : 47.08856391906738 W\n",
      "[codecarbon INFO @ 10:05:02] Energy consumed for all GPUs : 0.001474 kWh. All GPUs Power : 353.70300000000003 W\n",
      "[codecarbon INFO @ 10:05:02] Energy consumed for all CPUs : 0.000166 kWh. All CPUs Power : 39.877596251666446 W\n",
      "[codecarbon INFO @ 10:05:02] 0.001836 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 10:05:17] Energy consumed for RAM : 0.000392 kWh. RAM Power : 47.08856391906738 W\n",
      "[codecarbon INFO @ 10:05:17] Energy consumed for all GPUs : 0.002964 kWh. All GPUs Power : 357.88200000000006 W\n",
      "[codecarbon INFO @ 10:05:17] Energy consumed for all CPUs : 0.000332 kWh. All CPUs Power : 39.84626478680841 W\n",
      "[codecarbon INFO @ 10:05:17] 0.003689 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 10:05:21] Energy consumed for RAM : 0.000441 kWh. RAM Power : 47.08856391906738 W\n",
      "[codecarbon INFO @ 10:05:21] Energy consumed for all GPUs : 0.003329 kWh. All GPUs Power : 354.46500000000003 W\n",
      "[codecarbon INFO @ 10:05:21] Energy consumed for all CPUs : 0.000376 kWh. All CPUs Power : 42.036500744477536 W\n",
      "[codecarbon INFO @ 10:05:21] 0.004145 kWh of electricity used since the begining.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1377, training_loss=0.2946628717382316, metrics={'train_runtime': 33.7076, 'train_samples_per_second': 326.455, 'train_steps_per_second': 40.851, 'total_flos': 406183858377360.0, 'train_loss': 0.2946628717382316, 'epoch': 3.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\"test-trainer\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809f7f3b",
   "metadata": {},
   "source": [
    "### `Evaluate` library to compute model metrics\n",
    "\n",
    "The `evaluate` library proves very helpful here in computing the model performance metrics. Now, each dataset has its relevant metric for the task the model is trained for. In this case, it is `accuracy` and `F1` score. We can instantiate a `metric` object from a dataset, in much the same way that we used the `datasets.load()` to load the data.\n",
    "\n",
    "The `compute()` method takes as arguments what you would expect: the predictions and the ground-truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c11e2a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337adf6d",
   "metadata": {},
   "source": [
    "### The `Trainer` \n",
    "\n",
    "The trainer finally takes all the parts one would expect:\n",
    "\n",
    "* some specific training arguments, such as the name of the training run, an evaluation-strategy, etc.\n",
    "* `model` -- the model to train or fine tune\n",
    "* the training and validation datasets\n",
    "* the tokenizer\n",
    "* the relevant data collator\n",
    "* the function to compute the metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9119b0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[codecarbon INFO @ 10:05:21] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 10:05:21] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 10:05:21] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 10:05:21] [setup] CPU Tracking...\n",
      "[codecarbon INFO @ 10:05:21] Tracking Intel CPU via RAPL interface\n",
      "[codecarbon INFO @ 10:05:22] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 10:05:22]   Platform system: Linux-5.19.0-38-generic-x86_64-with-glibc2.35\n",
      "[codecarbon INFO @ 10:05:22]   Python version: 3.10.9\n",
      "[codecarbon INFO @ 10:05:22]   Available RAM : 125.570 GB\n",
      "[codecarbon INFO @ 10:05:22]   CPU count: 32\n",
      "[codecarbon INFO @ 10:05:22]   CPU model: 13th Gen Intel(R) Core(TM) i9-13900K\n",
      "[codecarbon INFO @ 10:05:22]   GPU count: 1\n",
      "[codecarbon INFO @ 10:05:22]   GPU model: 1 x NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\"test-trainer\", evaluation_strategy=\"epoch\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3af099",
   "metadata": {},
   "source": [
    "### Fine-tune the model\n",
    "\n",
    "In order to fine-tune the pre-trained model, let the `trainer` now fire off the training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e67613c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1377' max='1377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1377/1377 00:36, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.346711</td>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.882979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.481100</td>\n",
       "      <td>0.593656</td>\n",
       "      <td>0.850490</td>\n",
       "      <td>0.895369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.259200</td>\n",
       "      <td>0.705571</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.894366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 10:05:41] Energy consumed for RAM : 0.000196 kWh. RAM Power : 47.08856391906738 W\n",
      "[codecarbon INFO @ 10:05:41] Energy consumed for all GPUs : 0.001443 kWh. All GPUs Power : 346.274 W\n",
      "[codecarbon INFO @ 10:05:41] Energy consumed for all CPUs : 0.000178 kWh. All CPUs Power : 42.66688583978885 W\n",
      "[codecarbon INFO @ 10:05:41] 0.001817 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 10:05:56] Energy consumed for RAM : 0.000392 kWh. RAM Power : 47.08856391906738 W\n",
      "[codecarbon INFO @ 10:05:56] Energy consumed for all GPUs : 0.002894 kWh. All GPUs Power : 348.398 W\n",
      "[codecarbon INFO @ 10:05:56] Energy consumed for all CPUs : 0.000347 kWh. All CPUs Power : 40.59553536814495 W\n",
      "[codecarbon INFO @ 10:05:56] 0.003634 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 10:06:02] Energy consumed for RAM : 0.000472 kWh. RAM Power : 47.08856391906738 W\n",
      "[codecarbon INFO @ 10:06:02] Energy consumed for all GPUs : 0.003341 kWh. All GPUs Power : 262.50100000000003 W\n",
      "[codecarbon INFO @ 10:06:02] Energy consumed for all CPUs : 0.000417 kWh. All CPUs Power : 40.85465879405804 W\n",
      "[codecarbon INFO @ 10:06:02] 0.004230 kWh of electricity used since the begining.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1377, training_loss=0.29535167807673923, metrics={'train_runtime': 36.1305, 'train_samples_per_second': 304.563, 'train_steps_per_second': 38.112, 'total_flos': 406183858377360.0, 'train_loss': 0.29535167807673923, 'epoch': 3.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
